{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cyon1\\Desktop\\LLM_cls_sum\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "print(parent_dir)\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cyon1\\Desktop\\project\\venv\\Lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'huggingface.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.32s/it]\n",
      "c:\\Users\\cyon1\\Desktop\\project\\venv\\Lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'huggingface.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device 0: NVIDIA GeForce RTX 4090 Laptop GPU - Allocated: 6128.35 MB\n"
     ]
    }
   ],
   "source": [
    "# llama_api.py\n",
    "import os, sys\n",
    "## 상위 경로 추가\n",
    "from config.prompt.generate_prompt import generate_prompt\n",
    "from source.utils import check_gpu_allocation\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "api_token = os.getenv(\"HUGGINGFACE_API_TOKEN\")\n",
    "\n",
    "## 모델 parameter setting 및 모델 로드\n",
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    do_sample=False,\n",
    "    top_p = None,\n",
    "    temperature = None\n",
    "    # trust_remote_code = True\n",
    ")\n",
    "\n",
    "## 현재 GPU 스펙 및 allocation 현황 조회\n",
    "check_gpu_allocation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_document(document: list):\n",
    "\n",
    "    # print(f'for debug: {document}')\n",
    "    messages = []\n",
    "    for text in document:\n",
    "        generated_prompt = generate_prompt(text, \"summarize\")\n",
    "        message = [{\"role\": \"system\", \"content\": generated_prompt[\"role\"]}, \n",
    "                    {\"role\": \"user\", \"content\": generated_prompt[\"message\"]}]\n",
    "        # print(f\"debug: {message}\")\n",
    "        messages.append(message)\n",
    "    # print(f\"debug: {len(messages)}\")\n",
    "    try:\n",
    "        outputs = pipe(\n",
    "            messages,\n",
    "            max_new_tokens=12800,\n",
    "        )\n",
    "        response_message = [output[0][\"generated_text\"][-1][\"content\"] for output in outputs] \n",
    "        return {\"response\": response_message}\n",
    "    except Exception as e:\n",
    "        raise Exception(str(e))\n",
    "    \n",
    "\n",
    "\n",
    "def classify_topic(document: list):\n",
    "    messages = []\n",
    "    for text in document:\n",
    "        generated_prompt = generate_prompt(text, \"classify\")\n",
    "        # print(generated_prompt[\"message\"])\n",
    "        message = [{\"role\": \"system\", \"content\": generated_prompt[\"role\"]}, \n",
    "                    {\"role\": \"user\", \"content\": generated_prompt[\"message\"]}]\n",
    "        messages.append(message)\n",
    "    try:\n",
    "        outputs = pipe(\n",
    "            messages,\n",
    "            max_new_tokens=12800,\n",
    "        )\n",
    "        response_message = [output[0][\"generated_text\"][-1][\"content\"] for output in outputs]\n",
    "        return {\"response\": response_message}\n",
    "\n",
    "    except Exception as e:\n",
    "        raise Exception(str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "data_path = \"C:/Users/cyon1/Desktop/LLM_cls_sum/data/article_samples.xlsx\"\n",
    "data = pd.read_excel(data_path)\n",
    "\n",
    "original_documents = data[\"Articles\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Every year in November, people look for bargains on Black Friday. But did you know that the same day is also Buy Nothing Day?\\n\\nDo the preparation task first. Then read the article and do the exercises.\\n\\nWhat is Black Friday?\\nBlack Friday is the day after the American holiday of Thanksgiving, which is celebrated on the fourth Thursday of November. Because it is a holiday in the United States, it has long been a popular day for consumers to start shopping for Christmas. Over the last 20 years big retailers have started to offer discounts and bargains on this day, and it has become more and more popular. Last year, people in the USA spent an estimated $54.7 billion between Black Friday and Cyber Monday (the Monday after Thanksgiving, when people often buy more online). The idea of Black Friday has also spread around the world. For example, in 2017, people in the UK spent the equivalent of $10.3 billion, in Germany $7.6 billion and in France $6.2 billion.\\n\\nIs Black Friday out of control?\\nMany of us love to get a bargain, but some feel that events like Black Friday encourage people to buy things that they don’t really need and can’t afford. Many people seem to completely lose control of both their spending and their tempers. It is easy to find video online of customers physically fighting each other over bargains. It is also argued that Black Friday is bad for small shopkeepers, who cannot afford to offer the kinds of price cuts that the big companies can. \\n\\nWhat’s the alternative to Black Friday? \\nInstead of taking the opportunity to buy as much as possible on Black Friday, you could do the opposite and buy absolutely nothing. Since 1997, Buy Nothing Day has been held on the same day as Black Friday. The rules are simple. Just don’t buy anything at all for 24 hours. Many people are surprised how difficult this actually is. The aim is to make people think more about their spending and to make better decisions about what they buy and where they buy it from.\\n\\nEthical spending\\nAs well as spending less and not buying unnecessary items, Buy Nothing Day aims to raise awareness of how to be a more ethical consumer. For example, you can avoid buying ‘fast fashion’, that is, very cheap clothes that are worn a few times before being thrown away. Or you could decide not to automatically upgrade your mobile at the end of a contract. These kinds of decisions can help to protect the environment as well as saving you money. \\n\\nWhat else can you do on Buy Nothing Day? \\nSome people carry out protests at shopping centres. Others avoid the shops completely and go for a walk in nature instead. Another alternative, the Buy Nothing Coat Exchange, is an idea which is spreading. People donate winter coats throughout November and anyone who needs one can come and take one on Buy Nothing Day. ', \"The COP29 UN Climate Change Conference is taking place 11–22 November 2024, in Baku, Azerbaijan. The event brings together country leaders, experts and environmental campaigners to take urgent action against climate change.\\n\\nDo the preparation task first. Then read the article and do the exercises.\\n\\nPreparation\\nThe consequences of global warming are being seen all over the world. Droughts, floods, heatwaves and other extreme weather conditions are becoming more and more frequent. Polar ice caps are melting, and sea levels are rising. Climate change is a major threat to ecosystems and to humanity. Every year, world leaders meet at the COP summit to review the UN goal of limiting global temperature rise to 1.5 degrees Celsius and to discuss the action that still needs to be taken. \\n\\nWhat is a COP? \\nThis year the 29th United Nations Climate Change Conference will be held 11–22 November 2024, in Baku, Azerbaijan. The event is also known as COP29 – 'COP' stands for 'Conference of the Parties'. It usually takes place every year, and the venue, as well as the COP presidency, rotates among the five different UN regions (Africa, Asia, Latin America and the Caribbean, Central and Eastern Europe, and Western Europe and Others).\\n\\nThe Paris Agreement\\nThe Paris Agreement remains a key part of global climate efforts. This agreement was adopted in 2015, during the COP21 summit in Paris. With this agreement, almost every country in the world committed to cut CO2 emissions as rapidly as possible, in order to limit global warming to well below 2°C, aiming for 1.5°C. However, despite the commitments made in Paris, the progress made is not enough. The world is still failing to meet the targets necessary to avoid the worst effects of climate change.\\n\\nWhat are the aims of COP29?\\nThe goal of the COP29 conference is to take faster action to meet the targets of the Paris Agreement, with a focus on the finance required for countries to drastically reduce CO2 emissions. The 2024 event aims to:\\n\\nencourage countries to set more ambitious targets for reducing emissions, with the goal of limiting global warming to 1.5°C\\nincrease finance to help developing countries reduce emissions and adapt to climate change\\nensure an inclusive and fair process, particularly supporting developing countries in climate negotiations.\\nAs the effects of climate change become more and more devastating, it is crucial that country leaders, experts and environmental campaigners come together to work on the biggest challenge the world faces today.\\n\\nTask 1\"]\n"
     ]
    }
   ],
   "source": [
    "print(original_documents[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "summarized_documents = summarize_document(original_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "classified_documents = classify_topic(original_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': [\"{\\n'Politics': 0.00,\\n'Economics': 0.00,\\n'Social Issue': 0.40,\\n'Culture & Arts': 0.00,\\n'Natural Science': 0.00,\\n'International Affairs': 0.00,\\n'Technology & Internet': 0.00,\\n'Health & Wellness': 0.00,\\n'Travel': 0.00\\n}\",\n",
       "  \"Preparation complete.\\n\\nMain input text classification:\\n\\n{\\n'Politics': 0.60,\\n'International Affairs': 0.20,\\n'Natural Science': 0.10,\\n'Other': 0.10\\n}\",\n",
       "  \"{\\n    'Culture & Arts': 0.20,\\n    'History': 0.30,\\n    'Social Issue': 0.20,\\n    'Politics': 0.30\\n}\",\n",
       "  \"{\\n    'Sports': 0.80,\\n    'Culture & Arts': 0.15,\\n    'Other': 0.05\\n}\",\n",
       "  \"{\\n'Politics': 0.00,\\n'Natural Science': 0.00,\\n'Technology & Internet': 0.60,\\n'Economics': 0.00,\\n'Social Issue': 0.20,\\n'Culture & Arts': 0.00,\\n'International Affairs': 0.00,\\n'Health & Wellness': 0.20,\\n'Travel': 0.00\\n}\",\n",
       "  \"{\\n    'Politics': 0.80,\\n    'Culture & Arts': 0.05,\\n    'Economics': 0.05,\\n    'Social Issue': 0.05,\\n    'Natural Science': 0.05,\\n    'International Affairs': 0.05,\\n    'Technology & Internet': 0.00,\\n    'Health & Wellness': 0.00,\\n    'Travel': 0.00\\n}\"]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classified_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file = {\n",
    "    \"original_documents\": original_documents,\n",
    "    \"summarized_documents\": summarized_documents[\"response\"],\n",
    "    \"classified_documents\": classified_documents[\"response\"]\n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(save_file)\n",
    "df.to_excel(\"C:/Users/cyon1/Desktop/LLM_cls_sum/data/LLAMA3B_result.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
